{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "pre-training.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcruzr0609/pastillitas/blob/main/pre_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dress-division"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                    int(root.find('size')[0].text),\n",
        "                    int(root.find('size')[1].text),\n",
        "                    member[0].text,\n",
        "                    int(member[4][0].text),\n",
        "                    int(member[4][1].text),\n",
        "                    int(member[4][2].text),\n",
        "                    int(member[4][3].text)\n",
        "                    )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height',\n",
        "                'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ],
      "id": "dress-division",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "constitutional-fishing"
      },
      "source": [
        "import csv\n",
        "import xml.etree.cElementTree as ET\n",
        "\n",
        "def csv_to_xml(csv_path, resized_images_path, labels_path, folder):\n",
        "    f = open(csv_path, 'r')\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    old_filename = None\n",
        "    for row in reader:\n",
        "        filename = row[0]\n",
        "        if filename == old_filename:\n",
        "            object = ET.SubElement(annotation, 'object')\n",
        "            ET.SubElement(object, 'name').text = row[3]\n",
        "            ET.SubElement(object, 'pose').text = 'Unspecified'\n",
        "            ET.SubElement(object, 'truncated').text = '0'\n",
        "            ET.SubElement(object, 'difficult').text = '0'\n",
        "            bndbox = ET.SubElement(object, 'bndbox')\n",
        "            ET.SubElement(bndbox, 'xmin').text = row[4]\n",
        "            ET.SubElement(bndbox, 'ymin').text = row[5]\n",
        "            ET.SubElement(bndbox, 'xmax').text = row[6]\n",
        "            ET.SubElement(bndbox, 'ymax').text = row[7]\n",
        "        else:\n",
        "            if old_filename is not None:\n",
        "                labels_file = old_filename.replace('.jpg', '.xml')\n",
        "                tree = ET.ElementTree(annotation)\n",
        "                tree.write(labels_path + labels_file)\n",
        "\n",
        "            annotation = ET.Element('annotation')\n",
        "            ET.SubElement(annotation, 'folder').text = folder\n",
        "            ET.SubElement(annotation, 'filename').text = filename\n",
        "            ET.SubElement(annotation, 'path').text =     resized_images_path + filename\n",
        "            source = ET.SubElement(annotation, 'source')\n",
        "            ET.SubElement(source, 'database').text = 'Unknown'\n",
        "            size = ET.SubElement(annotation, 'size')\n",
        "            ET.SubElement(size, 'width').text = row[1]\n",
        "            ET.SubElement(size, 'height').text = row[2]\n",
        "            ET.SubElement(size, 'depth').text = '3'\n",
        "            ET.SubElement(annotation, 'segmented').text = '0'\n",
        "\n",
        "            object = ET.SubElement(annotation, 'object')\n",
        "            ET.SubElement(object, 'name').text = row[3]\n",
        "            ET.SubElement(object, 'pose').text = 'Unspecified'\n",
        "            ET.SubElement(object, 'truncated').text = '0'\n",
        "            ET.SubElement(object, 'difficult').text = '0'\n",
        "            bndbox = ET.SubElement(object, 'bndbox')\n",
        "            ET.SubElement(bndbox, 'xmin').text = row[4]\n",
        "            ET.SubElement(bndbox, 'ymin').text = row[5]\n",
        "            ET.SubElement(bndbox, 'xmax').text = row[6]\n",
        "            ET.SubElement(bndbox, 'ymax').text = row[7]\n",
        "        old_filename = filename\n",
        "    f.close()"
      ],
      "id": "constitutional-fishing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suburban-peter"
      },
      "source": [
        "from imgaug.augmentables.bbs import BoundingBoxesOnImage\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "aug = iaa.SomeOf(2, [\n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "    iaa.Affine(rotate=(-60, 60)),\n",
        "    iaa.Affine(translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3,   0.3)}),\n",
        "    iaa.Fliplr(1),\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03 * 255, 0.05 * 255)),\n",
        "    iaa.Add((-25, 25)),\n",
        "    iaa.MotionBlur(k=15),\n",
        "    iaa.MultiplySaturation((0.5, 1.5)),\n",
        "    iaa.LogContrast(gain=(0.6, 1.4)),\n",
        "    iaa.Flipud(1)\n",
        "])"
      ],
      "id": "suburban-peter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "complicated-dover"
      },
      "source": [
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "        image = imageio.imread(images_path+filename)\n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "\n",
        "        else:\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "id": "complicated-dover",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coordinated-award"
      },
      "source": [
        "def bbs_obj_to_df(bbs_object):\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs"
      ],
      "id": "coordinated-award",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "verified-ending"
      },
      "source": [
        "xml_df = xml_to_csv('xmls/')\n",
        "for i in range(10):\n",
        "    augmented_images_df = image_aug(xml_df, 'resized_images/', 'resized_images/', 'aug{}_'.format(i), aug)\n",
        "    augmented_images_df.to_csv('aug{}_images.csv'.format(i), index=False)\n",
        "    csv_to_xml(csv_path='aug{}_images.csv'.format(i),\n",
        "                resized_images_path='resized_images/', \n",
        "                labels_path='labels_path/',\n",
        "                folder='resized_images')\n",
        "    os.remove('aug{}_images.csv'.format(i))"
      ],
      "id": "verified-ending",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guilty-questionnaire"
      },
      "source": [
        "import os\r\n",
        "import shutil\r\n",
        "import random\r\n",
        "#grep \"<xmin />\" aug* for corrupted data\r\n",
        "images_path = 'resized_images/'\r\n",
        "labels_path = 'labels_path/'\r\n",
        "train_path = 'dataset/train/'\r\n",
        "validation_path = 'dataset/validation/'\r\n",
        "\r\n",
        "\r\n",
        "for image_file in os.listdir(images_path):\r\n",
        "    labels_file = image_file.replace('.jpg', '.xml')\r\n",
        "    if random.uniform(0, 1) > 0.2:\r\n",
        "        shutil.copy(images_path + image_file, train_path + 'images/'\r\n",
        "                    + image_file)\r\n",
        "        shutil.copy(labels_path + labels_file, train_path +\r\n",
        "                    'annotations/' + labels_file)\r\n",
        "    else:\r\n",
        "        shutil.copy(images_path + image_file, validation_path +\r\n",
        "                    'images/' + image_file)\r\n",
        "        shutil.copy(labels_path + labels_file, validation_path +\r\n",
        "                    'annotations/' + labels_file)"
      ],
      "id": "guilty-questionnaire",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brilliant-toolbox"
      },
      "source": [
        ""
      ],
      "id": "brilliant-toolbox",
      "execution_count": null,
      "outputs": []
    }
  ]
}